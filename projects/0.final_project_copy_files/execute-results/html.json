{
  "hash": "8521f3784792add81410795579667a78",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Wrangling for Sholl Analysis\"\nsubtitle: \"Intro to R Final Project\"\nauthor: \"Clara L. Hibbs\"\ndate: 2025-07-28\nformat: \n  html: \n    self-contained-math: true\neditor: source\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n# What is Known about Microglia?\n\nMicroglia are the resident immune cells of the central nervous system. These cells have several important functions related to *immune surveillance and response* which work to maintain brain homeostasis and protect from disease.\n\n-   [phagocytosis]{.underline} of dead cells, cellular debris, and protein aggregates\n\n-   [inflammatory response]{.underline} through secretion of pro- or anti-inflammatory cytokines\n\nAdditionally, microglia regulate [neurogenesis and synaptic plasticity]{.underline} through their phagocytic and secretory actions.\n\n------------------------------------------------------------------------\n\nIn healthy tissue, microglia exist in a \"resting\" state. This name is a bit of a misnomer as microglia are never resting. Homeostatic microglia are extremely dynamic cells which are constantly moving their processes in order to monitor the brain microenvironment.\n\nAlso contributing to their dynamic nature, is their ability to perform phenotypic switching in response to environmental stimuli. In a healthy brain, a majority of microglia are in a resting morphology which is defined by a ramified appearance. Upon encountering damage- or pathogen-associated molecular patterns, microglia become reactive and retract their processes to adopt an amoeboid morphology.\n\n![](figures/phenotypic_swtich.png){fig-align=\"center\"}\n\n# What is Sholl Analysis?\n\nThe characterization of microglia morphology is commonly used as a metric of microglia activation. This characterization is most often accomplished by measuring microglia complexity through Sholl analysis.\n\nSholl analysis applies concentric circles, each 1 um apart, to 2D or 3D renderings of microglia. The number of intersections that occur between the circles and the microglial processes are than quantified. This quantification is then used to estimate microglial complexity. More ramified, and less activated, microglia will have more intersections at radii farther from the cell soma. Amoeboid, and more activated, microglia will have less intersections.\n\n![](figures/sholl_wkflow.png){fig-align=\"center\"}\n\n# The Data\n\nThis project will be completed using a subset of Sholl analysis data that I have collected during my Ph.D. project.\n\n------------------------------------------------------------------------\n\n# The Code\n\nFirst thing is first, we need to load in some packages. For this script, I used **tidyverse** packages, **cowplot** for plotting, and a package called **here** which simplifies file paths.\n\n## Load Packages\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(cowplot)\nlibrary(here)\n```\n:::\n\n\n\n## Data Import\n\nData import is going to be a bit more complicated than usual. The Imaris software exports Sholl data in individual csv files (see below).\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 7\n  `Filament No. Sholl Intersections` Unit  Category Radius  Time        ID ...7 \n                               <dbl> <lgl> <chr>     <dbl> <dbl>     <dbl> <lgl>\n1                                  0 NA    Filament      0     1 100000000 NA   \n2                                  0 NA    Filament      1     1 100000000 NA   \n3                                  0 NA    Filament      2     1 100000000 NA   \n4                                  1 NA    Filament      3     1 100000000 NA   \n5                                  9 NA    Filament      4     1 100000000 NA   \n6                                 14 NA    Filament      5     1 100000000 NA   \n```\n\n\n:::\n:::\n\n\n\nThis table is from one output file. Each cell that is analyzed one of these files. I have up to 30 cells per animal resulting in an approximate total of 500 cells meaning I have 500 csv files to compare.\n\nTo get around importing each of those files separately, I have written some code loops. A loop is a statement that allows for a block of code to be executed repeatedly. I have written 2 loops for this data analysis which I will explain below.\n\nFor now, I have set 2 file paths. The **input path** leads to a folder that contains the raw output folders from Imaris. The **output path** leads to the folder that will store the output for the rest of the script.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set path to input files\ninput_path <- \"projects/data/240521_MG/21-32-07/Imaris\"\n\n# set path to output folder\noutput_path <- \"projects/data/Sholl_trim\"\n```\n:::\n\n\n\nImaris saves the output files, named \\*Detailed.csv, within a statistics folder for each cell analyzed. To speed up the process of importing each separate file, I am using the **list.files** command. This base R command lists out all of the files located in a specific directory. By setting the **path** as my input path, I told R to look in the folder that contains subdirectories with the \\*Detailed.csv files. I then set the **pattern** to recognize only the \\*Detailed.csv files. Setting **recursive** as true allows R to open the subdirectories within the Imaris folder. Setting **full.names** to true means that the entire relative file path will be listed instead of just the file name.\n\n\n\n::: {.cell depends-on='set_paths'}\n\n```{.r .cell-code}\n# open subfolders and find the *Detailed.csv files\ninput_files <- list.files(\n  path = input_path,\n  pattern = \"Detailed\\\\.csv$\",\n  recursive = TRUE,\n  full.names = TRUE)\n```\n:::\n\n\n\nThere is no output from this command as it is saved to input_files.\n\n## Data Transformation\n\nNow that all of the input files have been located, we can begin to remove unnecessary columns. Let's have a look at the data file again.\n\n![](figures/original.png){fig-align=\"center\" width=\"442\"}\n\nYou'll notice that the data does not begin until row 5 with column headers in row 4. Additionally, the data necessary for Sholl analysis are located in the \"Filament No. Sholl Intersections\" and \"Radius\" columns. The four other columns do not provide helpful data.\n\nBefore we combine all of the statistics files together, it would be smart to organize the individual files. I have written a loop that will do exactly that.\n\nFirst of all, the loop with repeat for each file listed by input_files. It will start with the first file and continue down the list until it completes all 17 files.\n\nThe first step of the loop is to **read** in the csv file. Using *skip = 4* means that the first 4 rows of each file will be skipped. This removes the 4 unnecessary rows of headers. Since the headers were removed, *col_names* is set to false.\n\nIn the next step, the data file is updated to only include the two columns containing Sholl data using **select**, and these columns are given headers using **rename**. Additionally, **mutate** is used to add a new column to the data file which includes the file path.\n\nFinally, the data file is given a new name and saved as a csv to the output file. Let's walk backwards through the code. The file name is extracted from the full file path using **basename**. The file extension (.csv) is then removed using **file_path_sans_ext**. The **paste0** function allows for \".trim.csv\" to be added to the end of the file name. The newly trimmed data file is then saved to the output folder with the new name.\n\n\n\n::: {.cell depends-on='import data'}\n\n```{.r .cell-code}\nfor (file in input_files) {\n  data <- read_csv(file, skip = 4, col_names = FALSE)\n  \n  trimmed <- data |>\n    mutate(filename = file) |>\n    select(filename, X1, X4) |>\n    rename(intersections = X1,\n           radius = X4)\n  \n  output_file <- file.path(output_path, paste0(tools::file_path_sans_ext(basename(file)), \".trim.csv\"))\n  write_csv(trimmed, output_file)\n}\n```\n:::\n\n\n\n## Data Combination\n\nNow we have a folder with several different csv files containing Sholl data for each analyzed cell. The next step is to combine these individual data files into one.\n\nFirst, we once again use **list.files** to create a list that contains all trimmed data files. The first file is then **read** into R and removes the rows that contain \"filename\" which is the header row. This row is removed to prevent repeated header columns in the final data frame. The remaining files are edited and eventually combined with a loop. The first file is excluded from the loop in order to create a data frame that the remaining data can be added to.\n\nThe loop starts the same as the previous code for the first file. Then the new data frame is added to the existing data frame containing the first file. The loop repeats until all of the files have been added to the combined data frame.\n\nThe column headers are then added and the combined file is written.\n\n\n\n::: {.cell depends-on='examine trimmed'}\n\n```{.r .cell-code}\nall_files <- list.files(here(\"projects/data/Sholl_trim\"), pattern = \"\\\\.csv$\", full.names = TRUE)\n\ndf <- read.csv(all_files[1], header = FALSE)\ndf <- df[df$V1 !=\"filename\", ]\n\nfor (i in 2:length(all_files)) {\n  tmp <- read.csv(all_files[i], header = FALSE)\n  tmp <- tmp[tmp$V1 !=\"filename\", ]\n  df <- rbind(df, tmp)\n  print(paste(\"Processed file\", i, \"of\", length(all_files)))\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Processed file 2 of 17\"\n[1] \"Processed file 3 of 17\"\n[1] \"Processed file 4 of 17\"\n[1] \"Processed file 5 of 17\"\n[1] \"Processed file 6 of 17\"\n[1] \"Processed file 7 of 17\"\n[1] \"Processed file 8 of 17\"\n[1] \"Processed file 9 of 17\"\n[1] \"Processed file 10 of 17\"\n[1] \"Processed file 11 of 17\"\n[1] \"Processed file 12 of 17\"\n[1] \"Processed file 13 of 17\"\n[1] \"Processed file 14 of 17\"\n[1] \"Processed file 15 of 17\"\n[1] \"Processed file 16 of 17\"\n[1] \"Processed file 17 of 17\"\n```\n\n\n:::\n\n```{.r .cell-code}\ncolnames(df) <- c(\"filename\", \"intersections\", \"radius\")\n\nwrite.csv(df, \"/Users/clara-hibbs/Documents/GitHub/clarahibbs/projects/data/Sholl.csv\", row.names = FALSE)\n```\n:::\n\n\n\nTaking a peek at the data frame shows that there are three columns. One contains the file path, and therefore the sample ID. The second and third contain the Sholl data.\n\n\n\n::: {.cell depends-on='file combination'}\n\n```{.r .cell-code}\nglimpse(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 735\nColumns: 3\n$ filename      <chr> \"projects/data/240521_MG/21-32-07/Imaris/21-32-07_100x_C…\n$ intersections <chr> \"0\", \"0\", \"0\", \"1\", \"9\", \"14\", \"16\", \"17\", \"23\", \"27\", \"…\n$ radius        <chr> \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", …\n```\n\n\n:::\n:::\n\n\n\n## Text to Column\n\nAs mentioned, each sample ID is currently stored in a file path. Obviously, this is not ideal. The file path can be separated into individual columns to isolate important sample information.\n\nTo preserve the integrity of the original file path column, the column is duplicated. The text in the duplicated column can be turned into individual columns using **separate_wider_delim**.\n\n\n\n::: {.cell depends-on='examine df'}\n\n```{.r .cell-code}\ndf$filename_copy <- df$filename\n\ndata <- separate_wider_delim(df, \n                             cols = filename_copy, \n                             names = c(\"folder1\", \"folder2\", \"folder3\", \"id\", \"folder5\", \"folder6\", \"Detailed\"), \n                             delim = \"/\")\nglimpse(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 735\nColumns: 10\n$ filename      <chr> \"projects/data/240521_MG/21-32-07/Imaris/21-32-07_100x_C…\n$ intersections <chr> \"0\", \"0\", \"0\", \"1\", \"9\", \"14\", \"16\", \"17\", \"23\", \"27\", \"…\n$ radius        <chr> \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", …\n$ folder1       <chr> \"projects\", \"projects\", \"projects\", \"projects\", \"project…\n$ folder2       <chr> \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", …\n$ folder3       <chr> \"240521_MG\", \"240521_MG\", \"240521_MG\", \"240521_MG\", \"240…\n$ id            <chr> \"21-32-07\", \"21-32-07\", \"21-32-07\", \"21-32-07\", \"21-32-0…\n$ folder5       <chr> \"Imaris\", \"Imaris\", \"Imaris\", \"Imaris\", \"Imaris\", \"Imari…\n$ folder6       <chr> \"21-32-07_100x_CA1_1_Statistics\", \"21-32-07_100x_CA1_1_S…\n$ Detailed      <chr> \"21-32-07_100x_CA1_c1_Detailed.csv\", \"21-32-07_100x_CA1_…\n```\n\n\n:::\n:::\n\n\n\nThe data frame now contains six new columns. However, four of these columns contain unnecessary information and can be removed from the data frame. Using **select**, the important columns were isolated in the data frame.\n\n\n\n::: {.cell depends-on='data organization'}\n\n```{.r .cell-code}\ndata <- data |>\n  select(id, filename, intersections, radius, Detailed)\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  id       filename                                intersections radius Detailed\n  <chr>    <chr>                                   <chr>         <chr>  <chr>   \n1 21-32-07 projects/data/240521_MG/21-32-07/Imari… 0             0      21-32-0…\n2 21-32-07 projects/data/240521_MG/21-32-07/Imari… 0             1      21-32-0…\n3 21-32-07 projects/data/240521_MG/21-32-07/Imari… 0             2      21-32-0…\n4 21-32-07 projects/data/240521_MG/21-32-07/Imari… 1             3      21-32-0…\n5 21-32-07 projects/data/240521_MG/21-32-07/Imari… 9             4      21-32-0…\n6 21-32-07 projects/data/240521_MG/21-32-07/Imari… 14            5      21-32-0…\n```\n\n\n:::\n:::\n\n\n\n## Text to Column... Again\n\nThe data frame now contains the sample ID, but the newly dubbed Detailed column still contains more crucial information. This information includes the subregion in which the cell was located and cell number. Text to columns can be used again to separate this information.\n\n\n\n::: {.cell depends-on='subset data'}\n\n```{.r .cell-code}\ndata <- separate_wider_delim(data,\n                             cols = Detailed,\n                             names = c(\"x1\", \"x2\", \"subregion\", \"cell\", \"x3\"),\n                             delim = \"_\")\nglimpse(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 735\nColumns: 9\n$ id            <chr> \"21-32-07\", \"21-32-07\", \"21-32-07\", \"21-32-07\", \"21-32-0…\n$ filename      <chr> \"projects/data/240521_MG/21-32-07/Imaris/21-32-07_100x_C…\n$ intersections <chr> \"0\", \"0\", \"0\", \"1\", \"9\", \"14\", \"16\", \"17\", \"23\", \"27\", \"…\n$ radius        <chr> \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", …\n$ x1            <chr> \"21-32-07\", \"21-32-07\", \"21-32-07\", \"21-32-07\", \"21-32-0…\n$ x2            <chr> \"100x\", \"100x\", \"100x\", \"100x\", \"100x\", \"100x\", \"100x\", …\n$ subregion     <chr> \"CA1\", \"CA1\", \"CA1\", \"CA1\", \"CA1\", \"CA1\", \"CA1\", \"CA1\", …\n$ cell          <chr> \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c…\n$ x3            <chr> \"Detailed.csv\", \"Detailed.csv\", \"Detailed.csv\", \"Detaile…\n```\n\n\n:::\n:::\n\n\n\nOnce again, the necessary columns can be isolated from the unnecessary ones using **select**. Additionally, more sample information can be added to the data frame. Based on the subregion isolated from the filename, the region can be inferred.\n\nTRUE \\~ NA_character\\_ ensures that any data that does not match either of the presented cases is labeled as NA.\n\n\n\n::: {.cell depends-on='data organization 2'}\n\n```{.r .cell-code}\ndata <- data |> select(id, subregion, cell, filename, intersections, radius) |>\n  rename(CellID = filename) |>\n  mutate(section = str_extract(subregion, \"\\\\d\"),\n         region_prefix = str_extract(subregion, \"[A-Z]+\"),\n         region = case_when(\n           region_prefix %in% c(\"CA\", \"DG\") ~ \"HPC\",\n           region_prefix %in% c(\"DS\", \"VS\") ~ \"STR\",\n           TRUE ~ NA_character_))\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 9\n  id    subregion cell  CellID intersections radius section region_prefix region\n  <chr> <chr>     <chr> <chr>  <chr>         <chr>  <chr>   <chr>         <chr> \n1 21-3… CA1       c1    proje… 0             0      1       CA            HPC   \n2 21-3… CA1       c1    proje… 0             1      1       CA            HPC   \n3 21-3… CA1       c1    proje… 0             2      1       CA            HPC   \n4 21-3… CA1       c1    proje… 1             3      1       CA            HPC   \n5 21-3… CA1       c1    proje… 9             4      1       CA            HPC   \n6 21-3… CA1       c1    proje… 14            5      1       CA            HPC   \n```\n\n\n:::\n:::\n\n\n\nFor the final time, the important data is isolated from the unneeded data columns. Additionally, **mutate** is used to convert the \"radius\" and \"intersections\" columns from character vectors to numeric vectors.\n\n\n\n::: {.cell depends-on='subset data 2'}\n\n```{.r .cell-code}\ndata <- data |> select(id, region, subregion, section, cell, CellID, intersections, radius)\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 8\n  id       region subregion section cell  CellID            intersections radius\n  <chr>    <chr>  <chr>     <chr>   <chr> <chr>             <chr>         <chr> \n1 21-32-07 HPC    CA1       1       c1    projects/data/24… 0             0     \n2 21-32-07 HPC    CA1       1       c1    projects/data/24… 0             1     \n3 21-32-07 HPC    CA1       1       c1    projects/data/24… 0             2     \n4 21-32-07 HPC    CA1       1       c1    projects/data/24… 1             3     \n5 21-32-07 HPC    CA1       1       c1    projects/data/24… 9             4     \n6 21-32-07 HPC    CA1       1       c1    projects/data/24… 14            5     \n```\n\n\n:::\n\n```{.r .cell-code}\ndata <- data |>\n  mutate(radius = as.numeric(as.character(radius))) |>\n  mutate(intersections = as.numeric(as.character(intersections)))\nglimpse(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 735\nColumns: 8\n$ id            <chr> \"21-32-07\", \"21-32-07\", \"21-32-07\", \"21-32-07\", \"21-32-0…\n$ region        <chr> \"HPC\", \"HPC\", \"HPC\", \"HPC\", \"HPC\", \"HPC\", \"HPC\", \"HPC\", …\n$ subregion     <chr> \"CA1\", \"CA1\", \"CA1\", \"CA1\", \"CA1\", \"CA1\", \"CA1\", \"CA1\", …\n$ section       <chr> \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"…\n$ cell          <chr> \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c…\n$ CellID        <chr> \"projects/data/240521_MG/21-32-07/Imaris/21-32-07_100x_C…\n$ intersections <dbl> 0, 0, 0, 1, 9, 14, 16, 17, 23, 27, 20, 19, 19, 15, 16, 3…\n$ radius        <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16…\n```\n\n\n:::\n\n```{.r .cell-code}\nwrite.csv(data, \"/Users/clara-hibbs/Documents/GitHub/clarahibbs/projects/data/Sholl.csv\", row.names = FALSE)\n```\n:::\n\n\n\n## Metadata Time!\n\nWhile the data has been parsed as much as possible, data is still missing from the file. These missing factors include variables such as sex, group, and age which are needed for data comparison. This data is readily accessible in a metadata file that I previously made. This metadata file can be applied to the data frame to match the correct variables to each sample ID.\n\nFirst, the metadata file is **read** into R.\n\n\n\n::: {.cell depends-on='data organization 3'}\n\n```{.r .cell-code}\nmeta <- read.csv(\"/Users/clara-hibbs/Documents/GitHub/clarahibbs/projects/data/240521_MG/meta_sholl.csv\", header = TRUE, stringsAsFactors = FALSE, colClasses = \"character\")\nhead(meta)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        id litter group  trt sex months  age\n1 21-32-07  21-32   CON none   F     25 aged\n```\n\n\n:::\n:::\n\n\n\n**Merge** is used to combine the data frame with the metadata file. Merge will automatically match the \"id\" columns and applies the remaining metadata columns correctly.\n\n\n\n::: {.cell depends-on='import metadata'}\n\n```{.r .cell-code}\ndata <- merge(data, meta)\nglimpse(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 735\nColumns: 14\n$ id            <chr> \"21-32-07\", \"21-32-07\", \"21-32-07\", \"21-32-07\", \"21-32-0…\n$ region        <chr> \"HPC\", \"HPC\", \"HPC\", \"HPC\", \"HPC\", \"HPC\", \"HPC\", \"HPC\", …\n$ subregion     <chr> \"CA1\", \"CA1\", \"CA1\", \"CA1\", \"CA1\", \"CA1\", \"CA1\", \"CA1\", …\n$ section       <chr> \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"…\n$ cell          <chr> \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c…\n$ CellID        <chr> \"projects/data/240521_MG/21-32-07/Imaris/21-32-07_100x_C…\n$ intersections <dbl> 0, 0, 0, 1, 9, 14, 16, 17, 23, 27, 20, 19, 19, 15, 16, 3…\n$ radius        <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16…\n$ litter        <chr> \"21-32\", \"21-32\", \"21-32\", \"21-32\", \"21-32\", \"21-32\", \"2…\n$ group         <chr> \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", …\n$ trt           <chr> \"none\", \"none\", \"none\", \"none\", \"none\", \"none\", \"none\", …\n$ sex           <chr> \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"…\n$ months        <chr> \"25\", \"25\", \"25\", \"25\", \"25\", \"25\", \"25\", \"25\", \"25\", \"2…\n$ age           <chr> \"aged\", \"aged\", \"aged\", \"aged\", \"aged\", \"aged\", \"aged\", …\n```\n\n\n:::\n:::\n\n\n\nThe dataset is then reorganized using **relocate** to place all of the metadata columns together.\n\n\n\n::: {.cell depends-on='merge data and meta'}\n\n```{.r .cell-code}\ndata <- data |> relocate(9:14, .after=id)\nglimpse(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 735\nColumns: 14\n$ id            <chr> \"21-32-07\", \"21-32-07\", \"21-32-07\", \"21-32-07\", \"21-32-0…\n$ litter        <chr> \"21-32\", \"21-32\", \"21-32\", \"21-32\", \"21-32\", \"21-32\", \"2…\n$ group         <chr> \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", \"CON\", …\n$ trt           <chr> \"none\", \"none\", \"none\", \"none\", \"none\", \"none\", \"none\", …\n$ sex           <chr> \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"…\n$ months        <chr> \"25\", \"25\", \"25\", \"25\", \"25\", \"25\", \"25\", \"25\", \"25\", \"2…\n$ age           <chr> \"aged\", \"aged\", \"aged\", \"aged\", \"aged\", \"aged\", \"aged\", …\n$ region        <chr> \"HPC\", \"HPC\", \"HPC\", \"HPC\", \"HPC\", \"HPC\", \"HPC\", \"HPC\", …\n$ subregion     <chr> \"CA1\", \"CA1\", \"CA1\", \"CA1\", \"CA1\", \"CA1\", \"CA1\", \"CA1\", …\n$ section       <chr> \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"…\n$ cell          <chr> \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c…\n$ CellID        <chr> \"projects/data/240521_MG/21-32-07/Imaris/21-32-07_100x_C…\n$ intersections <dbl> 0, 0, 0, 1, 9, 14, 16, 17, 23, 27, 20, 19, 19, 15, 16, 3…\n$ radius        <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16…\n```\n\n\n:::\n:::\n\n\n\nWe can use **table** to quickly examine the data.\n\n\n\n::: {.cell depends-on='metadata organization'}\n\n```{.r .cell-code}\ntable(data$id)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n21-32-07 \n     735 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(data$group)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCON \n735 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(data$sex)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  F \n735 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(data$age)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\naged \n 735 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(data$subregion)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCA1 DG1 DG2 DS1 DS2 VS1 VS2 \n110  67  72 138 154 137  57 \n```\n\n\n:::\n:::\n\n\n\n# Sholl Analysis\n\nThe data has now been fully wrangled and is ready for analysis! As this is an introduction to R class, we'll just do some simple plotting with ggplot.\n\n\n\n\n\n\n\nAs the data represents microglia populations in four different regions of the brain, we'll make a plot for each and combine them at the end.\n\nFor the first plot, we will **filter** the data to only include data from the dorsal striatum. We can then pipe to ggplot and assign radius to the x-axis and intersections to the y-axis. Using **geom_smooth** fits a smoothed line to the data. The addition of **stat_summary** to the code adds the mean and standard error to each point. Then, aesthetic changes are made to the plot. This is repeated for each subregion.\n\n\n\n::: {.cell depends-on='examine dataset'}\n\n```{.r .cell-code}\na <- data |> filter(str_starts(subregion, \"DS\")) |>\n  ggplot(aes(x=radius, y=intersections)) +\n  geom_smooth(se=FALSE, color = \"palegreen4\") +\n  stat_summary(fun.data=mean_se, geom=\"pointrange\", color = \"palegreen4\") +\n  theme_cowplot() +\n  labs(subtitle = \"Dorsal Striatum\") +\n  coord_cartesian(xlim = c(0,60), ylim = c(0,30)) +\n  theme(legend.position = \"none\") +\n  xlab(\"Radius (um)\") + \n  ylab(\"Number of Intersections\")\n```\n:::\n\n::: {.cell depends-on='examine dataset'}\n\n```{.r .cell-code}\nb <- data |> filter(str_starts(subregion,\"VS\")) |>\n  ggplot(aes(x=radius, y=intersections)) +\n  geom_smooth(se=FALSE, color = \"sienna3\") +\n  stat_summary(fun.data=mean_se, geom=\"pointrange\", color = \"sienna3\") +\n  theme_cowplot() +\n  labs(subtitle = \"Ventral Striatum\") +\n  coord_cartesian(xlim = c(0,60), ylim = c(0,30)) +\n  theme(legend.position = \"none\") +\n  xlab(\"Radius (um)\") + \n  ylab(\"Number of Intersections\")\n```\n:::\n\n::: {.cell depends-on='examine dataset'}\n\n```{.r .cell-code}\nc <- data |> filter(str_starts(subregion, \"DG\")) |>\n  ggplot(aes(x=radius, y=intersections)) +\n  geom_smooth(se=FALSE, color = \"skyblue4\") +\n  stat_summary(fun.data=mean_se, geom=\"pointrange\", color = \"skyblue4\") +\n  theme_cowplot() +\n  labs(subtitle = \"Dentate Gyrus\") +\n  coord_cartesian(xlim = c(0,60), ylim = c(0,30)) +\n  theme(legend.position = \"none\") +\n  xlab(\"Radius (um)\") + \n  ylab(\"Number of Intersections\")\n```\n:::\n\n::: {.cell depends-on='examine dataset'}\n\n```{.r .cell-code}\nd <- data |> filter(subregion == \"CA1\") |>\n  ggplot(aes(x=radius, y=intersections)) +\n  geom_smooth(se=FALSE, color = \"orchid4\") +\n  stat_summary(fun.data=mean_se, geom=\"pointrange\", color = \"orchid4\", ) +\n  theme_cowplot() +\n  labs(subtitle = \"CA1\") +\n  coord_cartesian(xlim = c(0,60), ylim = c(0,30)) +\n  theme(legend.position = \"none\") +\n  xlab(\"Radius (um)\") + \n  ylab(\"Number of Intersections\")\n```\n:::\n\n\n\nNow that plotting commands have been made for each subregion, **plot_grid** can be used to combine the 4 plots into one figure. To add a title to the combined plot, a drawing layer is added with **ggdraw**.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncombined <- plot_grid(a, b, c, d, nrow = 2)\n\nfinal_plot <- plot_grid(ggdraw() +\n                          draw_label(\"Microglia Complexity in Different Aged Brain Regions\", fontface = \"bold\", size = 14),\n                        combined,\n                        ncol =1,\n                        rel_heights = c(0.1, 1))\n\nprint(final_plot)\n```\n\n::: {.cell-output-display}\n![](0.final_project_copy_files/figure-html/combine plots-1.png){width=672}\n:::\n:::\n\n\n\nWith the completion of this project, I have written a script that I can use in my Ph.D. project. This script will greatly simplify the process of data wrangling for Sholl data which has been time consuming and prone to human error in the past.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.3 (2025-02-28)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] here_1.0.1      cowplot_1.1.3   lubridate_1.9.4 forcats_1.0.0  \n [5] stringr_1.5.1   dplyr_1.1.4     purrr_1.0.4     readr_2.1.5    \n [9] tidyr_1.3.1     tibble_3.3.0    ggplot2_3.5.2   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.6         generics_0.1.4     lattice_0.22-6     stringi_1.8.7     \n [5] hms_1.1.3          digest_0.6.37      magrittr_2.0.3     evaluate_1.0.4    \n [9] grid_4.4.3         timechange_0.3.0   RColorBrewer_1.1-3 fastmap_1.2.0     \n[13] Matrix_1.7-2       rprojroot_2.0.4    jsonlite_2.0.0     mgcv_1.9-1        \n[17] scales_1.4.0       cli_3.6.5          rlang_1.1.6        crayon_1.5.3      \n[21] bit64_4.6.0-1      splines_4.4.3      withr_3.0.2        yaml_2.3.10       \n[25] tools_4.4.3        parallel_4.4.3     tzdb_0.5.0         vctrs_0.6.5       \n[29] R6_2.6.1           lifecycle_1.0.4    htmlwidgets_1.6.4  bit_4.6.0         \n[33] vroom_1.6.5        pkgconfig_2.0.3    pillar_1.11.0      gtable_0.3.6      \n[37] glue_1.8.0         xfun_0.52          tidyselect_1.2.1   rstudioapi_0.17.1 \n[41] knitr_1.50         dichromat_2.0-0.1  farver_2.1.2       nlme_3.1-167      \n[45] htmltools_0.5.8.1  labeling_0.4.3     rmarkdown_2.29     compiler_4.4.3    \n```\n\n\n:::\n:::\n",
    "supporting": [
      "0.final_project_copy_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}